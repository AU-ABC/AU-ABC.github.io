[
  {
    "objectID": "tips/R.html",
    "href": "tips/R.html",
    "title": "Useful tips for R",
    "section": "",
    "text": "Useful tips for R"
  },
  {
    "objectID": "tips/bash.html",
    "href": "tips/bash.html",
    "title": "Useful tips for day-to-day bash",
    "section": "",
    "text": "awk '$2~/^-$/ { next } { print }' file_input &gt; file_output\n\n\n\nawk -F \"\\\"*,\\\"*\" '{print $M}' file.csv\n\n\n\nawk '{ $1=\"\"; $2=\"\"; print}' filename\n\n\n\nsed -n '10,20p' myFile\n\n\n\nsed -n -e 1p -e 2p  myFile\n\n\n\n sed -n '$L~$Mp' myFile\n\n\n\ncut -f1 20141020.combined_mask.whole_genomeV2.bed | sort -n | uniq -c\n\n\n\nsed -e \"s/string1/string2/\" myFile \n\n\n\nsort -k 3,3 myFile\n\n\n\ngrep -v -e \"pattern\" myFile &gt; newFile\n\n\ngrep -v -n -e \"pattern\" myFile | cut -f1 -d\":\"\n\ngrep -v -e \"pattern1\\|pattern2\" myFile &gt; newFile\n\n\n\n\n\n\n\necho $a $b $c | tr -s ' ' '\\t'\n\n\n\nperl -E \"say $a + $b\"\n\n\n\n\n\n\nls *.zip | xargs -n 1 basename -s .zip\n\n\n\nfind . -type f ! -name '*.gz' -exec gzip \"{}\" \\;\n\n\n\n\n\n\nwget -i file.txt\n\n\n\nfor var in `ls -d */`; do echo ${var::-1}; done"
  },
  {
    "objectID": "tips/bash.html#handling-text-files",
    "href": "tips/bash.html#handling-text-files",
    "title": "Useful tips for day-to-day bash",
    "section": "",
    "text": "awk '$2~/^-$/ { next } { print }' file_input &gt; file_output\n\n\n\nawk -F \"\\\"*,\\\"*\" '{print $M}' file.csv\n\n\n\nawk '{ $1=\"\"; $2=\"\"; print}' filename\n\n\n\nsed -n '10,20p' myFile\n\n\n\nsed -n -e 1p -e 2p  myFile\n\n\n\n sed -n '$L~$Mp' myFile\n\n\n\ncut -f1 20141020.combined_mask.whole_genomeV2.bed | sort -n | uniq -c\n\n\n\nsed -e \"s/string1/string2/\" myFile \n\n\n\nsort -k 3,3 myFile\n\n\n\ngrep -v -e \"pattern\" myFile &gt; newFile\n\n\ngrep -v -n -e \"pattern\" myFile | cut -f1 -d\":\"\n\ngrep -v -e \"pattern1\\|pattern2\" myFile &gt; newFile"
  },
  {
    "objectID": "tips/bash.html#handling-variables",
    "href": "tips/bash.html#handling-variables",
    "title": "Useful tips for day-to-day bash",
    "section": "",
    "text": "echo $a $b $c | tr -s ' ' '\\t'\n\n\n\nperl -E \"say $a + $b\""
  },
  {
    "objectID": "tips/bash.html#managing-files",
    "href": "tips/bash.html#managing-files",
    "title": "Useful tips for day-to-day bash",
    "section": "",
    "text": "ls *.zip | xargs -n 1 basename -s .zip\n\n\n\nfind . -type f ! -name '*.gz' -exec gzip \"{}\" \\;"
  },
  {
    "objectID": "tips/bash.html#transfering-files",
    "href": "tips/bash.html#transfering-files",
    "title": "Useful tips for day-to-day bash",
    "section": "",
    "text": "wget -i file.txt\n\n\n\nfor var in `ls -d */`; do echo ${var::-1}; done"
  },
  {
    "objectID": "documentation/2024-06-27-ABC2.html",
    "href": "documentation/2024-06-27-ABC2.html",
    "title": "ABC.2: RStudio projects and Anaconda+Python",
    "section": "",
    "text": "The following tutorials show how to create a package environment and do some basic analysis in both R and python."
  },
  {
    "objectID": "documentation/2024-06-27-ABC2.html#project-creation-and-management-in-rstudio",
    "href": "documentation/2024-06-27-ABC2.html#project-creation-and-management-in-rstudio",
    "title": "ABC.2: RStudio projects and Anaconda+Python",
    "section": "Project creation and management in RStudio",
    "text": "Project creation and management in RStudio\n1. Open RStudioo, go to the menu and select File –&gt; New Project...\n2. Choose New Directory –&gt; New Project (similarly you can create a project in an existing folder). Note that there is a third version including version control: here you can also control the history of all changes in the project files using version control tools (such as Git), but we are not talking about this for now.\n\n3. Name your project and select the directory where you want to save it. Click on use renv for this project. Finally click Create Project\n4. The project is now established. You can see some files are automatically created into the project directory.\n\n\n\n\n\n\nNote\n\n\n\nWhen you want to open your project the next time, you can either: - Open the project by double-clicking on the file in Windows Explorer/OSX Finder (e.g. MyProject.Rproj) - Open RStudio, go to the menu and select File –&gt; Open Project and browser to find and select the project that you want to open - Open RStudio, go to the menu, select File –&gt; Recent Projects, and select the project from the list of most recently opened projects\nSome of the things making it nice to work in projects in RStudio are that when a project is opened:\n\nA new R session (process) is started\nThe .RData file (saved data) in the project’s main directory is loaded\nThe .Rhistory file (command history) in the project’s main directory is loaded\nThe current working directory is set to the project directory\nPackages in the environment are loaded\nAnd other settings are restored to where they were the last time the project was closed\n\n\n\n\nProject structure\nA clean and organised project structure is super important. To ensure this, a good practice is to create subfolders like Data, Scripts, Output, and Docs within your project directory. You can do all this in the RStudio browser (bottom-right corner)."
  },
  {
    "objectID": "documentation/2024-06-27-ABC2.html#using-the-renv-package-to-manage-a-projects-environment",
    "href": "documentation/2024-06-27-ABC2.html#using-the-renv-package-to-manage-a-projects-environment",
    "title": "ABC.2: RStudio projects and Anaconda+Python",
    "section": "Using the renv package to manage a project’s environment",
    "text": "Using the renv package to manage a project’s environment\nThe renv package allows you to create isolated and reproducible environments for your R projects, ensuring that the exact package versions and dependencies are used, ultimately facilitating reproducibility and collaboration. For an extended description, read more here. Dependencies are packages on which others rely on to work.\nKey features:\n\nEach project can have its own set of R packages and versions\nEnsures that the same package versions are used each time the project is run\nManages dependencies by automatically tracking the packages used in your project and their versions\nEnsures the same environment setup when sharing projects with collaborators\n\n\ntracking installed packages with renv\nYou do not need much to track all your packages. Simply create your files with R code and save them inside your project folder. While you code, you will necessarily install some packages which you need to create your program.\nWhen you are done, run in the Rstudio console the program renv::snapshot() - this will update the file renv.lock with a list of all installed packages and dependencies (open the file to see how it looks like). All the packages are installed inside the renv folder and will be loaded from there.\nNote that renv will track only packages that are used in your files with code - other packages which are installed but not used will not be tracked. Pretty smart!\n1. Now, try to install dplyr and ggplot2 using\ninstall.packages(c(\"dplyr\", \"ggplot2\"))\nin the RStudio console.\n2. Snapshot the environment by running\nrenv::snapshot()\nHave a look at the file renv.lock to see how it looks like. It should not show any package beyond renv: the file is updated only with packages used in the scripts you have in the project folder, so we will have to run the snapshot at the end of the tutorial where we use the packages!\n\n\n\n\n\n\nSharing projects\n\n\n\nWhen sharing your project, include the renv.lock and renv directory in the project folder. You can also include just the file renv.lock. Other users can use renv::activate() to activate the environment, and also renv::restore() if they need to install the packages (in case the folder renv is not provided).\nNote that if you provide the folder renv, this must be used in the same operating system. It might not be possible to use the environment folder create, for example, in Linux, on a windows or mac computer."
  },
  {
    "objectID": "documentation/2024-06-27-ABC2.html#kickstart-dplyr-analysis",
    "href": "documentation/2024-06-27-ABC2.html#kickstart-dplyr-analysis",
    "title": "ABC.2: RStudio projects and Anaconda+Python",
    "section": "Kickstart dplyr analysis",
    "text": "Kickstart dplyr analysis\nThe dplyr package is part of the tidyverse, a set of packages all based on consistent and intuitive syntax/grammar for data manipulation, where the fundamental data structure is the data frame. dplyr is one of the most popular packages for data manipulation.\nWe already install the package in our environment and it is ready to use. You can use the following commands in the Console, or create an R script or an R markdown document.\nCreate a small dataset with gene expressions and some patient meta data:\n\n# Load dplyr\nlibrary(dplyr)\n\n# Create the dataframe\ndata &lt;- data.frame(\n  SampleID = c(\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"),\n  Gene1 = c(5.2, 6.3, 4.9, 7.2, 5.8),\n  Gene2 = c(3.8, 2.7, 3.5, 4.1, 3.9),\n  Gene3 = c(7.1, 8.5, 6.8, 9.2, 7.3),\n  Age = c(45, 52, 37, 50, 43),\n  Treatment = c(\"A\", \"B\", \"A\", \"B\", \"A\"),\n  Response = c(\"Responder\", \"Non-Responder\", \"Responder\", \"Non-Responder\", \"Responder\")\n)\n\n\ndata\n\n\nA data.frame: 5 × 7\n\n\nSampleID\nGene1\nGene2\nGene3\nAge\nTreatment\nResponse\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nS1\n5.2\n3.8\n7.1\n45\nA\nResponder\n\n\nS2\n6.3\n2.7\n8.5\n52\nB\nNon-Responder\n\n\nS3\n4.9\n3.5\n6.8\n37\nA\nResponder\n\n\nS4\n7.2\n4.1\n9.2\n50\nB\nNon-Responder\n\n\nS5\n5.8\n3.9\n7.3\n43\nA\nResponder\n\n\n\n\n\nYou can apply many commands very intuitively with dplyr. For example, to select only the gene expressions:\n\nselected_data &lt;- select(data, Gene1, Gene2, Gene3)\n\nselected_data\n\n\nA data.frame: 5 × 3\n\n\nGene1\nGene2\nGene3\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n5.2\n3.8\n7.1\n\n\n6.3\n2.7\n8.5\n\n\n4.9\n3.5\n6.8\n\n\n7.2\n4.1\n9.2\n\n\n5.8\n3.9\n7.3\n\n\n\n\n\nYou can establish any filter based on the columns or combination of them. Filtering only on age of at least 50yo and rate of Gene1 and Gene2 larger than 2 is as below\n\nfiltered_data &lt;- filter(data, Age&gt;50 & Gene1/Gene2&gt;2)\n\nfiltered_data\n\n\nA data.frame: 1 × 7\n\n\nSampleID\nGene1\nGene2\nGene3\nAge\nTreatment\nResponse\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n\n\n\n\nS2\n6.3\n2.7\n8.5\n52\nB\nNon-Responder\n\n\n\n\n\nAdding new columns as a combination of others is also immediate\n\nmutated_data &lt;- mutate(data, GeneTotal = Gene1 + Gene2 + Gene3)\n\nmutated_data\n\n\nA data.frame: 5 × 8\n\n\nSampleID\nGene1\nGene2\nGene3\nAge\nTreatment\nResponse\nGeneTotal\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n\n\n\n\nS1\n5.2\n3.8\n7.1\n45\nA\nResponder\n16.1\n\n\nS2\n6.3\n2.7\n8.5\n52\nB\nNon-Responder\n17.5\n\n\nS3\n4.9\n3.5\n6.8\n37\nA\nResponder\n15.2\n\n\nS4\n7.2\n4.1\n9.2\n50\nB\nNon-Responder\n20.5\n\n\nS5\n5.8\n3.9\n7.3\n43\nA\nResponder\n17.0\n\n\n\n\n\nNow we introduce the pipe symbol %&gt;%. This combines with the dplyr functions such that subsequent operations between pipes reflect the way we enunciate them orally. For example: The dataframe data must be grouped by treatment and for each group summarise the Gene1 by its average. Arrange the result by the average of Gene1 in descending order.\n\n\n\n\n\n\ndataframes and tibbles\n\n\n\nNote how the output is no longer a dataframe, but a tibble. A tibble is a more “modern” version of the dataframe which is used in the tidyverse packages. You cannot really notice much difference when using them. To ensure you are using a tibble , you can always define a dataframe and transform it into a tibble using the command as_tibble. Read more about tibbles at this link.\n\n\n\ngrouped_data &lt;- data %&gt;% \n                group_by(Treatment) %&gt;% \n                summarise(avgGene1 = mean(Gene1)) %&gt;%\n                arrange( desc(avgGene1) )\n\ngrouped_data\n\n\nA tibble: 2 × 2\n\n\nTreatment\navgGene1\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n\n\n\n\nB\n6.75\n\n\nA\n5.30\n\n\n\n\n\nTo save your table in the Output folder as csv file:\n\nwrite.csv(grouped_data, \"Output/grouped.csv\")\n\nNow, if you ran all the commands in your console, create a new R script (File -&gt; New -&gt; R Script) and paste all the code used until now, then save it. If you instead used a Script or Markdown, save it. Move the script/markdown file into the Code folder, so you keep the files organized! Now run again\nrenv::snapshot()\nYou should be requested for permission to write some packages into renv.lock. Accept and look into the file, which not should be different and including new package names.\n\n\n\n\n\n\nwrap up\n\n\n\nNow you know how to manage a project in RStudio and the packages you need. dplyr and the other packages pivoting around tidyverse have a plethora of useful functionalities. A good place to start from is to use a table you need for your own work, and try out various things you can do. Some good resources for training are available as links below:\n\nA chapter of R for data science from the data carpentry. Go through it and look at other chapters as well, they are very instructive!\nA cheatsheet for all dplyr manipulation and for other important tidyverse packages + Rstudio. Keep some at your desk!"
  },
  {
    "objectID": "documentation/2024-06-27-ABC2.html#install-anaconda-and-create-an-environment",
    "href": "documentation/2024-06-27-ABC2.html#install-anaconda-and-create-an-environment",
    "title": "ABC.2: RStudio projects and Anaconda+Python",
    "section": "Install Anaconda and create an environment",
    "text": "Install Anaconda and create an environment\n1. Download Anaconda from the download page. Uso also the Sign In button of the webpage to create an account: this will enable you to use an AI-chat showing up while you code, and which can help you doing a lot of things.\n\n\n\n\n\n\nNote\n\n\n\nThis guide has been made with Windows, and works similarly with MacOS. For Linux, you will download a file with .sh extension, which you can execute in the command line with bash installer.sh.\n\n\n2. Once Anaconda is installed, open Anaconda Navigator. Log into Anaconda Cloud from the software, and eventually update Anaconda Navigator if asked.\n3. Your initial window would look similarly as below. What you can see is a suite of softwares. Some of those are installed and they are found in the anaconda environment called base (root), as shown in the red circle. It is good advice not to modify the base environment, because Anaconda itself is installed into it!\n\n4. We create a new environment with only few needed packages for our tutorial. Click on Environments on the toolbar (red circle). You can see the base (root) environment and a long list of packages it contains. Click on Create (blue circle).\n\n5. In the appearing window choose a name for the environment and select Python. Then click on Create. It takes a bit of time to create the environment.\n\n6. Select the environment. It will load a few packages (just Python and its essential dependencies), but we want to install new ones. Open the filtering menu (green circle above) and choose All to view all existing packages. Select the following packages: pandas, numpy, jupyterlab, anaconda-toolbox, seaborn and click Apply. A list of dependencies will be shown, and you have to accept that to continue. Wait for the installations to go through.\n7. Now select the environment again. There are much more packages installed and ready to use. Click on Home in the toolbar: you will see the softwares installed in your environment (choose Installed Application from the dropdown menu to see only the installed ones).\n\n\n\n\n\n\nwrap up\n\n\n\nYou can create various environments to keep specific versions of packages constant in separate data science projects. This ensures a high degree of reproducibility in your projects.\nAn environment can include the softwares needed to code (RStudio, jupyterLab are the most famous, but also others can be installed).\nWe will use the created environment to run some basic commands in python."
  },
  {
    "objectID": "documentation/2024-06-27-ABC2.html#python-basics",
    "href": "documentation/2024-06-27-ABC2.html#python-basics",
    "title": "ABC.2: RStudio projects and Anaconda+Python",
    "section": "Python basics",
    "text": "Python basics\nHere we look at the python basics: variables, arrays and dataframes. We will immediately work with two packages: numpy and pandas, which make the use of arrays and dataframes very flexible.\n\nJupyterLab\nLaunch jupyterlab from the Anaconda Home, using the environment ABC2. You should be able to see Jupyterlab opened in your internet browser. It will look similar to the one below: it has a file browser, can show the opened files on different tabs, and has a coding window where the opened file is shown. When you first open jupyterlab you will instead see a Launcher, which gives you a choice for all the available things to do, usually Notebooks, Console, or Other, with related available languages.\n\nYou do not create projects in JupyterLab, you simply create folders instead.\n\nUse the browser to create a folder wherever you prefere, and organize it into subfolders: Code, Output, Data, Scripts. You can use the small button above the browser to create a folder, or simply the right-click options.\nAgain with a right click, create a notebook inside the Code folder\nWhen asked to choose a kernel, select python 3. A kernel includes the programming language and its packages as we installed them into the environment using Anaconda.\n{fig-align=“center”, width=300px}\n\nA notebook looks like this:\n\nThe gray area is a code cell, where you can write code. Select the left border out of a cell to\n\ntransform it into a Markdown cell where you can write text: key M of your keyboard\nadd a cell below: key B\nrun the cell and add one below: keys Shift+Enter\n\n\n\n\n\n\n\nTip\n\n\n\nA notebook looks a lot like a text file. When you open it, it will show all results and images from your code! You can share it to anyone without the need to run the code again for the recipient, if it is needed to simply show some results.\nThe webpage you are reading now has been created with a notebook!\n\n\nLet’s turn things into practice now. Transform the first cell into markdown (key M) and write a title with\n ## ABC2 is cool\nand press Shift+Enter. You will get a new cell below, and the text will be formatted from Markdown.\nNow we write some code in the new cell and press Shift+Enter to execute:\n\nimport numpy as np\nimport pandas as pd\n\nprint(\"Hello ABC\")\nx = np.arange(1,10)\ny = x**2\nprint(\"x\")\nprint(x)\nprint(\"y\")\nprint(y)\n\nHello ABC\nx\n[1 2 3 4 5 6 7 8 9]\ny\n[ 1  4  9 16 25 36 49 64 81]\n\n\nThings should look as below:\n\nThe little number on the left shows how many code steps you have been running so far. The code imports relevant libraries and shortens their name with np and pd, which makes coding easier and compact. Then we use the library np to define an array of numbers from 1 to 10, and we square this array assigning it to y. Finally we print the two arrays.\nAll variables are assigned with the = symbol and you can do all arithmetic operations:\n\nprint(2+3)\nprint(9*2)\nprint(5**2)\n\n5\n18\n25\n\n\n\n\nPandas dataframes\nwe procees looking into a small dataframe. Let’s create one using the pandas library\n\n# Create the dataframe\ndata = pd.DataFrame({\n    'SampleID': ['S1', 'S2', 'S3', 'S4', 'S5'],\n    'Gene1': [5.2, 6.3, 4.9, 7.2, 5.8],\n    'Gene2': [3.8, 2.7, 3.5, 4.1, 3.9],\n    'Gene3': [7.1, 8.5, 6.8, 9.2, 7.3],\n    'Age': [45, 52, 37, 50, 43],\n    'Treatment': ['A', 'B', 'A', 'B', 'A'],\n    'Response': ['Responder', 'Non-Responder', 'Responder', 'Non-Responder', 'Responder']\n})\n\n# View the dataframe\ndata\n\n\n\n\n\n\n\n\nSampleID\nGene1\nGene2\nGene3\nAge\nTreatment\nResponse\n\n\n\n\n0\nS1\n5.2\n3.8\n7.1\n45\nA\nResponder\n\n\n1\nS2\n6.3\n2.7\n8.5\n52\nB\nNon-Responder\n\n\n2\nS3\n4.9\n3.5\n6.8\n37\nA\nResponder\n\n\n3\nS4\n7.2\n4.1\n9.2\n50\nB\nNon-Responder\n\n\n4\nS5\n5.8\n3.9\n7.3\n43\nA\nResponder\n\n\n\n\n\n\n\nYou can plot variables from the dataframe with the package seaborn. For example\n\nimport seaborn as sns\n\nsns.scatterplot(data=data,\n                x=\"Gene1\",\n                y=\"Gene2\",\n                hue=\"Response\",\n                size=\"Age\"\n               )\n\n\n\n\n\n\n\n\nIn the command above we used some options beyond x and y. Can you see what they match in the plot?\n\n\n\n\n\n\nTip\n\n\n\nThe seaborn package webpage has great examples for any kind of plot you desire!\n\n\nThere are lots of summary statistics already implemented in python. Below we calculate mean, median and standard deviation for the column Gene1 of the data frame and then we print them.\n\nx = data.Gene1\nmeanG1 = np.mean(x)\nmedianG1 = np.median(x)\nsdG1 = np.std(x)\n\nprint(\"mean, median and sd:\")\n[meanG1, medianG1, sdG1]\n\nmean, median and sd:\n\n\n[np.float64(5.88), np.float64(5.8), np.float64(0.8182909018191513)]\n\n\nThis was neat! Can you try to calculate the cumulative sum of the difference between Gene1 and Gene2?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe answer is\nx = data.Gene1 - data.Gene2\ncsum = np.cumsum(x)\nprint(\"cumulative sum of Gene1 - Gene2:\")\nprint(csum)\n\n\n\n\n\nFunctions\nAlthough python and the packages you can find have almost everything you will need, sometimes you might need to define your own function. The syntax to do it is very easy: you define a function name, which then you will be able to use it. Below, there is a function taking an argument (arg1) and multiplying it by 5. The output needs to be explicit through the return() function.\n\ndef myFunction(arg1):\n    res = arg1 * 5\n    return(res)\n\nSuch a function works if the argument is a number, but also if it is an array!\n\nprint(\"with a number only\")\nprint( myFunction(5) )\nprint(\"with an array\")\nprint( myFunction(data.Gene1) )\n\nwith a number only\n25\nwith an array\n0    26.0\n1    31.5\n2    24.5\n3    36.0\n4    29.0\nName: Gene1, dtype: float64\n\n\nTry to make a function that takes three vectors, plots the first against the sum of the second and third, and returns the sum of all three vectors. Use the plot command we applied previously for help.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe answer is\ndef simpleSumPlot(arg1, arg2, arg3):\n    arg23 = arg2 + arg3\n    arg123 = arg1 + arg2 + arg3\n\n    #plotting\n    fig = sns.scatterplot(x = arg1, \n                    y = arg2)\n    fig.set_title(\"Plot with my own function\")\n    fig\n\n    return(arg123)\nNow you can try this on vectors of the same length. We can use the ones in our data frame!\n\nsimpleSumPlot(arg1 = data.Gene1,\n             arg2 = data.Gene2,\n             arg3 = data.Gene3)\n\n\n\n\n\nRead and write files\nSave a dataframe with the command .to_csv\n\ndata.to_csv('../Ouput/data.csv')\n\nAnd read it again using\n\ndata2 = pd.read_csv('../Ouput/data.csv')\n\n\ndata2\n\n\n\n\n\n\n\n\nUnnamed: 0\nSampleID\nGene1\nGene2\nGene3\nAge\nTreatment\nResponse\n\n\n\n\n0\n0\nS1\n5.2\n3.8\n7.1\n45\nA\nResponder\n\n\n1\n1\nS2\n6.3\n2.7\n8.5\n52\nB\nNon-Responder\n\n\n2\n2\nS3\n4.9\n3.5\n6.8\n37\nA\nResponder\n\n\n3\n3\nS4\n7.2\n4.1\n9.2\n50\nB\nNon-Responder\n\n\n4\n4\nS5\n5.8\n3.9\n7.3\n43\nA\nResponder\n\n\n\n\n\n\n\n\n\n\n\n\n\nwrap up\n\n\n\nYou learned how to use jupyterlab notebooks and how to do basic operations and plots with python."
  },
  {
    "objectID": "about/about.html",
    "href": "about/about.html",
    "title": "About the Sandbox",
    "section": "",
    "text": "An infrastructure project for health data science training and research in Denmark\nThe National Health Data Science Sandbox project kicked off in 2021 with 5 years of funding via the Data Science Research Infrastructure initiative from the Novo Nordisk Foundation. Health data science experts at five Danish universities are contributing to the Sandbox with coordination from the Center for Health Data Science under lead PI Professor Anders Krogh. Data scientists hosted in the research groups of each PI are building infrastructure and training modules on Computerome and UCloud, the primary academic high performance computing (HPC) platforms in Denmark. If you have any questions or would like to get in touch with one of our data scientists, please contact us here.\n\n\n\n\n\nOur computational ‘sandbox’ allows data scientists to explore datasets, tools and analysis pipelines in the same high performance computing environments where real research projects are conducted. Rather than a single, hefty environment, we’re deploying modularized topical environments tailored for independent use on each HPC platform. We aim to support three key user groups based at Danish universities:\n\ntrainees: use our training modules to learn analysis techniques with some guidance and guardrails - for your data type of interest AND for general good practices for HPC environments\n\nresearchers: prototype your tools and algorithms with an array of good quality datasets that are GDPR compliant and free to access\neducators: develop your next course with computational assignments in the HPC environment your students will use for their research\n\nActivity developing independent training modules and hosting workshops has centered on UCloud, while collaborative construction of a flexible Course Platform has been completed on Computerome for use by the Sandbox and independent educators. Publicly sourced datasets are being used in training modules on UCloud, while generation of synthetic data is an ongoing project at Computerome. Sandbox resources are under active construction, so check out our other pages for the current status on HPC Access, Datasets, and Modules. We run workshops using completed training modules on a regular basis and provide active support for Sandbox-hosted courses through a slack workspace. See our Contact page for more information.\n\n\nPartner with the Sandbox\nThe Sandbox welcomes proposals for new courses, modules, and prototyping projects from researchers and educators. We’d like to partner with lecturers engaged with us in developing needed materials collaboratively - we would love to have input from subject experts or help promote exciting new tools and analysis methods via modules! Please contact us with your ideas at nhds_sandbox@sund.ku.dk.\n\nWe thank the Novo Nordisk Foundation for funding support. If you use the Sandbox for research or reference it in text or presentations, please acknowledge the Health Data Science Sandbox project and its funder the Novo Nordisk Foundation (grant number NNF20OC0063268)."
  },
  {
    "objectID": "news/upcoming/2024-06-27-session2.html",
    "href": "news/upcoming/2024-06-27-session2.html",
    "title": "ABC.2: Second ABC session",
    "section": "",
    "text": "The second session of the ABC (Accessible Bioinformatics Cafe) will be on june 27th, at 13:00 in the hall of AIAS (the Aarhus Institute of Advanced Studies, see below).\nEveryone is welcome to join independently of coding skills and level."
  },
  {
    "objectID": "news/upcoming/2024-06-27-session2.html#agenda",
    "href": "news/upcoming/2024-06-27-session2.html#agenda",
    "title": "ABC.2: Second ABC session",
    "section": "Agenda",
    "text": "Agenda\nWe have a very minimalistic agenda consisting of\n\nWhat’s new\nAccessible topic presentation\nTutorials and Open Coding\n\nThe tutorials we propose are of increasing difficulty (and documented) at each meeting. This time we have a choice of\n\nA small dplyr project managed with RStudio\nInstall Anaconda and python basics"
  },
  {
    "objectID": "news/upcoming/2024-06-27-session2.html#signing-up",
    "href": "news/upcoming/2024-06-27-session2.html#signing-up",
    "title": "ABC.2: Second ABC session",
    "section": "Signing up",
    "text": "Signing up\nNo signup is really necessary, but if you just want to ensure there is enough cake, click on the button below to give us a heads up of your presence. Don’t do it multiple times to cheat for extra cake!\n \n\n Sign up for cake"
  },
  {
    "objectID": "news/past/test.html",
    "href": "news/past/test.html",
    "title": "Example",
    "section": "",
    "text": "Test post"
  },
  {
    "objectID": "workshop/workshop_april2024.html#access-sandbox-resources",
    "href": "workshop/workshop_april2024.html#access-sandbox-resources",
    "title": "Sandbox Workshop",
    "section": "Access Sandbox resources",
    "text": "Access Sandbox resources\nOur first choice is to provide all the training materials, tutorials, and tools as interactive apps on UCloud, the supercomputer located at the University of Southern Denmark. Anyone using these resources needs the following:\n\na Danish university ID so you can sign on to UCloud via WAYF1.\n\n \n\n for UCloud Access click here \n\n \n\nbasic ability to navigate in Linux/RStudio/Jupyter. You don’t need to be an expert, but it is beyond our ambitions (and course material) to teach you how to code from zero and how to run analyses simultaneously. We recommend a basic R or Python course before diving in.\nFor workshop participants: Use our invite link to the correct UCloud workspace that will be shared on the day of the workshop. This way, we can provide you with compute resources for the active sessions of the workshop2 Click the link below after your first uCloud access and accept the invite that shows.\n\n \n\n Invite link to uCloud workspace \n\n   \n\n\n\n\n\n\nNote\n\n\n\nOur apps can run on other clusters, simply by pulling a so-called docker container. You only need to have either docker or singularity installed on the cluster. GenomeDK supports singularity and thus can run our learning material as well. Ask us if you want to help the apps out of uCloud. Instructions will soon be available within our HPC access instructions."
  },
  {
    "objectID": "workshop/workshop_april2024.html#our-omics-apps",
    "href": "workshop/workshop_april2024.html#our-omics-apps",
    "title": "Sandbox Workshop",
    "section": "Our OMICS apps",
    "text": "Our OMICS apps\nThe agenda starts with an introduction to High Performance Computing (HPC) and uCloud. You will try two apps during the workshop, but we are developing others, and have deployed three apps already.\n \n\n\n\nProteomics Sandbox: Our sandbox modern with a suite of proteomics analysis tools, used for example in clinical proteomics. This app is not alone, since our data scientist Jacob has also made the app ColabFold on UCloud, with methods for protein structure prediction.\n\n\n \n\n\n\nTranscriptomics Sandbox : Our sandbox for bulk or single-cell RNA sequencing analysis and visualization - amongst others two regular workshops and provides stand-alone visualization tools. In the next update, we will introduce advanced tutorials for more complex single-cell RNA sequencing analysis from some of our supported courses.\n\n\n \n\n\n\nGenomics Sandbox: Our sandbox NGS data analysis and applications range from genome assembly to variant calling to metagenomics. We have currently a semester-long population genomics course and an NGS course with many applications (alignment, VCF analysis, bulk-RNA data, single-cell RNA sequencing)"
  },
  {
    "objectID": "workshop/workshop_april2024.html#discussion-and-feedback",
    "href": "workshop/workshop_april2024.html#discussion-and-feedback",
    "title": "Sandbox Workshop",
    "section": "Discussion and feedback",
    "text": "Discussion and feedback\nWe hope you enjoyed the live demo. If you have broader questions, suggestions, or concerns, now is the time to raise them! If you are totally toast for the day, remember that you can check out longer versions of our tutorials as well as other topics and tools in each of the Sandbox modules or join us for a multi-day in-person course (follow our news here).\nAs data scientists, we also would be really happy for some quantifiable info and feedback - we want to build things that the Danish health data science community is excited to use. Please answer these 5 questions for us before you head out for the day 3.\n \n\n\n\n\n\n\n\nNice meeting you and we hope to see you again!"
  },
  {
    "objectID": "workshop/workshop_april2024.html#footnotes",
    "href": "workshop/workshop_april2024.html#footnotes",
    "title": "Sandbox Workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOther institutions (e.g. hospitals, libraries, …) can log on through WAYF. See all institutions here↩︎\nTo use Sandbox materials outside of the workshop: remember that each new user has hundreds of hours of free computing credit and around 50GB of free storage, which can be used to run any uCloud software. If you run out of credit (which takes a long time) you’ll need to check with the local DeiC office at your university about how to request compute hours on UCloud. Contact us at the Sandbox if you need help or want more information.↩︎\nlink activated on day one of the workshop.↩︎"
  },
  {
    "objectID": "workshop/workshopAAU_2023.html",
    "href": "workshop/workshopAAU_2023.html",
    "title": "\nSandbox Workshop\n",
    "section": "",
    "text": "Sandbox Workshop\n!!! info “Upcoming Workshop at AAU”  Intro to the Health Data Science Sandbox at Aalborg University"
  },
  {
    "objectID": "workshop/workshopAAU_2023.html#the-sandbox-concept",
    "href": "workshop/workshopAAU_2023.html#the-sandbox-concept",
    "title": "\nSandbox Workshop\n",
    "section": "The Sandbox concept",
    "text": "The Sandbox concept\nThe Health Data Science Sandbox aims to be a training resource for bioinformaticians, data scientists, and those generally curious about how to investigate large biomedical datasets. We are an active and developing project seeking interested users (both trainees and educators). All of our open-source materials are available on our Github page and much more information is available on the rest of the website you are currently visiting! We work with both UCloud and Computerome (major Danish academic supercomputers) - see our HPC Access page for more info on each set up."
  },
  {
    "objectID": "workshop/workshopAAU_2023.html#access-sandbox-resources",
    "href": "workshop/workshopAAU_2023.html#access-sandbox-resources",
    "title": "\nSandbox Workshop\n",
    "section": "Access Sandbox resources",
    "text": "Access Sandbox resources\nWe currently provide training materials and resources as topical apps on UCloud, the supercomputer located at the University of Southern Denmark. To use these resources, you’ll need the following:\n\nLog onto UCloud at the address http://cloud.sdu.dk using your university credentials.\nthe ability to navigate in linux / RStudio / Jupyter. You don’t need to be an expert, but it is beyond our ambitions (and course material) to teach you how to code and how to run analyses simultaneously. We recommend a basic R or Python course before diving in.\n\nNote:\n\nTo use Sandbox materials outside of the workshop, you can request a project by clicking on apply for resources in your uCloud dashboard.\nIf you are a BSc or MSc student, you need a supervisor to apply on your behalf, or you can try to apply yourself mentioning the supervisor approval in the application.\nRemember, however, that you have 1000Kr of computing credit, and around 50GB of free storage to work on uCLoud."
  },
  {
    "objectID": "workshop/workshopAAU_2023.html#try-out-our-transcriptomics-module",
    "href": "workshop/workshopAAU_2023.html#try-out-our-transcriptomics-module",
    "title": "\nSandbox Workshop\n",
    "section": "Try out our transcriptomics module",
    "text": "Try out our transcriptomics module\nSo our Sandbox data scientists have finished their intro at the workshop? Great, now the brave ones in the audience can try out one of our apps in a live session. Today we are demoing:\n ### Transcriptomics If you’re interested in bulk or single cell RNA sequencing analysis and visualization, join Sandbox Data Scientist Samuele Soraggi from Aarhus University in testing out our Transcriptomics Sandbox app.\nFollow these instructions to try our app:\n\nClick on the button below to join the project for today: &lt;!DOCTYPE html&gt;\n\n\n\n\n\n&lt;p&gt;Green Button&lt;/p&gt;\n\n\n\n\n\nGo to Link\n\n\nYou should see a message on your browser where you have to accept the invitation to the project. This will add you to a project on uCloud, where we have data and extra computing credit for the course.\nBe sure you have joined the project. Check if you have the project OMICS workshop from the project menu (red circle). Afterwards, click on the App menu (green circle) \n\nFind the app Transcriptomics Sandbox (red circle), which is under the title Featured.\n\n\n\n\nClick on it. You will get into the settings window. Choose any Job Name (Nr 1 in the figure below), how many hours you want to use for the job (Nr 2; choose at least 3 hours, you can increase this later), and how many CPUs (Nr 3, choose at least 4 CPUs). Choose the course RNAseq in RStudio from the drop-down menu (Nr 4). Finally, click on the blue button Add Folder.\n\n\n\nNow, click on the browsing bar that appears (red circle).\n\n\n\nIn the appearing window, you should see already a folder called Intro_to_scRNAseq_R. Click on Use at its right (red circle)\n\n\n\nAfterwards, you should have something like this in the settings page:\n\n\n\nNow, click on Submit to start the app (the button is on the right side of the settings page)\nYou will now enter a waiting queue. When the session starts, the timer begins to count down (red circle), and you should be able to open the interface through the button (green circle). Note the buttons to add time to your session (blue circle) and the button to stop the session when you are done (pink circle)\n\n\n\nOpen the interface by clicking on the button (green circle of figure above). Sometimes you are warned of a missing connection: simply refresh the page. You will enter Rstudio, well-known interface to code in R.\nRun the following command to download the tutorial: download.file(\"https://raw.githubusercontent.com/hds-sandbox/ELIXIR-workshop/main/Notebooks/scRNAseq_Tutorial_R.Rmd\", \"tutorial_scrna.Rmd\")\nOpen the file tutorial_scrnaR.Rmd that should now appear in the file browser of Rstudio. Click now on visual (on the tool bar) if you need to see the tutorial in a more readable format.\nThe executable code is inside chunks (called cells) to be executed in order from the first to the last using the little green arrow appearing on the right side of each code cell.\nRead carefully through the tutorial and execute the code cells. You will see the outputs appearing as you proceed."
  },
  {
    "objectID": "workshop/workshopAAU_2023.html#discussion-and-feedback",
    "href": "workshop/workshopAAU_2023.html#discussion-and-feedback",
    "title": "\nSandbox Workshop\n",
    "section": "Discussion and feedback",
    "text": "Discussion and feedback\nWe hope you enjoyed the live demo. If you have broader questions, suggestions, or concerns, now is the time to raise them! If you are totally toast for the day, remember that you can check out longer versions of our tutorials as well as other topics and tools in each of the Sandbox modules or join us for a multi-day in person course.\nAs data scientists, we also would be really happy for some quantifiable info and feedback - we want to build things that the Danish health data science community is excited to use. Please answer these 5 questions for us before you head out for the day (link activated on day of the workshop).\n\nNice meeting you and we hope to see you again!"
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "The ABC will routinely post new meetings and related workshops/courses of interest here.\n\n\n\n\n\n\n\n\n\n\n\n\nABC.1: First ABC session\n\n\n\nCafe\n\n\nCoding\n\n\nBioinformatics\n\n\n\nCoding and bioinformatics for anyone!\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nABC.2: Second ABC session\n\n\n\nCafe\n\n\nCoding\n\n\nBioinformatics\n\n\n\nCoding and bioinformatics (and cake) for anyone!\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Event title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nEvent title\n\n\nDates\n\n\nLocation\n\n\nOrganizers\n\n\n\n\n\n\nExample\n\n\n2024-06-13\n\n\nAIAS hall, AU campus\n\n\nHDS Sandbox, Bioinf Core facility\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshop/workshop_june24.html",
    "href": "workshop/workshop_june24.html",
    "title": "\nWelcome to the homepage for our in-person bulk RNAseq workshop. Thank you for joining us!\n",
    "section": "",
    "text": "The Health Data Science Sandbox aims to be a training resource for bioinformaticians, data scientists, and those generally curious about how to investigate large biomedical datasets. We are an active and developing project seeking interested users (both trainees and educators). All of our open-source materials are available on our Github page and can be used on a computing cluster! We work with both UCloud, GenomeDK and Computerome, the major Danish academic supercomputers. See our HPC Access page for more info on each setup."
  },
  {
    "objectID": "workshop/workshop_june24.html#access-sandbox-resources",
    "href": "workshop/workshop_june24.html#access-sandbox-resources",
    "title": "\nWelcome to the homepage for our in-person bulk RNAseq workshop. Thank you for joining us!\n",
    "section": "Access Sandbox resources",
    "text": "Access Sandbox resources\nOur first choice is to provide all the training materials, tutorials, and tools as interactive apps on UCloud, the supercomputer located at the University of Southern Denmark. Anyone using these resources needs the following:\n\nDanish university credentials to sign on to UCloud via WAYF1.\n\n \n\n for UCloud Access click here \n\n \n\nBasic ability to navigate in Linux/RStudio/Jupyter. You don’t need to be an expert, but it is beyond our ambitions (and course material) to teach you how to code from zero and how to run analyses simultaneously. We recommend a basic R or Python course before diving in.\nFor workshop participants: Use our invite link to the correct UCloud workspace that will be shared on the day of the workshop. This way, we can provide you with compute resources for the active sessions of the workshop2 Click the link below after your first uCloud access and accept the invite that shows.\n\n \n\n Invite link to uCloud workspace \n\n   \n\n\n\n\n\n\nNote\n\n\n\nOur apps can run on other clusters, simply by pulling a so-called docker container. You only need to have either docker installed on the cluster."
  },
  {
    "objectID": "workshop/workshop_june24.html#our-sandbox-apps",
    "href": "workshop/workshop_june24.html#our-sandbox-apps",
    "title": "\nWelcome to the homepage for our in-person bulk RNAseq workshop. Thank you for joining us!\n",
    "section": "Our Sandbox apps",
    "text": "Our Sandbox apps\nThe agenda starts with an introduction to High Performance Computing (HPC) and uCloud.\n\nTo get started in our transcriptomics app, click here\n\n\n\n\nTranscriptomics Sandbox : Our sandbox for bulk or single-cell RNA sequencing analysis and visualization - amongst others two regular workshops and provides stand-alone visualization tools. In the next update, we will introduce advanced tutorials for more complex single-cell RNA sequencing analysis from some of our supported courses. - Click here to start setting up the app - To run nf-core RNAseq pipeline follow the instructions here\n\n\n \nWe are developing other apps. If you are interested, explore our modules section on our website!"
  },
  {
    "objectID": "workshop/workshop_june24.html#discussion-and-feedback",
    "href": "workshop/workshop_june24.html#discussion-and-feedback",
    "title": "\nWelcome to the homepage for our in-person bulk RNAseq workshop. Thank you for joining us!\n",
    "section": "Discussion and feedback",
    "text": "Discussion and feedback\nWe hope you enjoyed the live demo. If you have broader questions, suggestions, or concerns, now is the time to raise them! If you are totally toast for the day, remember that you can check out longer versions of our tutorials as well as other topics and tools in each of the Sandbox modules or join us for a multi-day in-person course (follow our news here).\nAs data scientists, we also would be really happy for some quantifiable info and feedback - we want to build things that the Danish health data science community is excited to use. Please answer these 5 questions for us before you head out for the day 3.\n \n\n\n\n\n\n\n\nNice meeting you and we hope to see you again!"
  },
  {
    "objectID": "workshop/workshop_june24.html#footnotes",
    "href": "workshop/workshop_june24.html#footnotes",
    "title": "\nWelcome to the homepage for our in-person bulk RNAseq workshop. Thank you for joining us!\n",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOther institutions (e.g. hospitals, libraries, …) can log on through WAYF. See all institutions here↩︎\nTo use Sandbox materials outside of the workshop: remember that each new user has hundreds of hours of free computing credit and around 50GB of free storage, which can be used to run any uCloud software. If you run out of credit (which takes a long time) you’ll need to check with the local DeiC office at your university about how to request compute hours on UCloud. Contact us at the Sandbox if you need help or want more information.↩︎\nlink activated on day one of the workshop.↩︎"
  },
  {
    "objectID": "workshop/workshop_Conference2023.html",
    "href": "workshop/workshop_Conference2023.html",
    "title": "\nSandbox Workshop\n",
    "section": "",
    "text": "Sandbox Workshop"
  },
  {
    "objectID": "workshop/workshop_Conference2023.html#the-sandbox-concept",
    "href": "workshop/workshop_Conference2023.html#the-sandbox-concept",
    "title": "\nSandbox Workshop\n",
    "section": "The Sandbox concept",
    "text": "The Sandbox concept\nThe Health Data Science Sandbox aims to be a training resource for bioinformaticians, data scientists, and those generally curious about how to investigate large biomedical datasets. We are an active and developing project seeking interested users (both trainees and educators). All of our open-source materials are available on our Github page and much more information is available on the rest of the website you are currently visiting! We work with both UCloud and Computerome (major Danish academic supercomputers) - see our HPC Access page for more info on each set up."
  },
  {
    "objectID": "workshop/workshop_Conference2023.html#access-sandbox-resources",
    "href": "workshop/workshop_Conference2023.html#access-sandbox-resources",
    "title": "\nSandbox Workshop\n",
    "section": "Access Sandbox resources",
    "text": "Access Sandbox resources\nWe currently provide training materials and resources as topical apps on UCloud, the supercomputer located at the University of Southern Denmark. To use these resources, you’ll need the following:\n\na Danish university ID so you can sign on to UCloud via WAYF. See this guide and/or follow along with our live demo.\nthe ability to navigate in linux / RStudio / Jupyter. You don’t need to be an expert, but it is beyond our ambitions (and course material) to teach you how to code and how to run analyses simultaneously. We recommend a basic R or Python course before diving in.\nour invite link to the correct UCloud project that will be shared on the day of the workshop. This way, we can provide you compute resources for the active sessions of the workshop. To use Sandbox materials outside of the workshop, you’ll need to check with the local DeiC office at your university about how to request compute hours on UCloud."
  },
  {
    "objectID": "workshop/workshop_Conference2023.html#try-out-a-module",
    "href": "workshop/workshop_Conference2023.html#try-out-a-module",
    "title": "\nSandbox Workshop\n",
    "section": "Try out a module",
    "text": "Try out a module\nSo our Sandbox data scientists have finished their intro at the workshop? Great, now it’s time to choose your poison (cough) topic of interest for today. Your options are below:\n ### Genomics If you’re interested in NGS technologies and applications ranging from genome assembly to variant calling to metagenomics, join Sandbox Data Scientist Samuele Soraggi in testing out our Genomics Sandbox app. This app supports a semester-length course on NGS as well as a Population Genomics course run regularly at Aarhus University. Sign into UCloud and then click this invite link.\n ### Transcriptomics If you’re interested in bulk or single cell RNA sequencing analysis and visualization, join Sandbox Data Scientist Jose Alejandro Romero Herrera (Alex) in testing out our Transcriptomics Sandbox app. This app supports regular 3-4 day workshops at University of Copenhagen and provides stand-alone visualisation tools. Sign into UCloud and then click this invite link.\n ### Proteomics Interested in modern methods for protein structure prediction? Join Sandbox Data Scientist Jacob Fredegaard Hansen as he walks you through how to use ColabFold on UCloud. Jacob can also demo our Proteomics Sandbox, which contains a suite of proteomics analysis tools that will support a future course in clinical proteomics but is already available on UCloud for interested users. Sign into UCloud and then click this invite link."
  },
  {
    "objectID": "workshop/workshop_Conference2023.html#discussion-and-feedback",
    "href": "workshop/workshop_Conference2023.html#discussion-and-feedback",
    "title": "\nSandbox Workshop\n",
    "section": "Discussion and feedback",
    "text": "Discussion and feedback\nWe hope you enjoyed the live demo. If you have broader questions, suggestions, or concerns, now is the time to raise them! If you are totally toast for the day, remember that you can check out longer versions of our tutorials as well as other topics and tools in each of the Sandbox modules or join us for a multi-day in person course.\nAs data scientists, we also would be really happy for some quantifiable info and feedback - we want to build things that the Danish health data science community is excited to use. Please answer these 5 questions for us before you head out for the day (link activated on day of the workshop).\n\nNice meeting you and we hope to see you again!"
  },
  {
    "objectID": "news/upcoming/2024-06-13-session1.html",
    "href": "news/upcoming/2024-06-13-session1.html",
    "title": "ABC.1: First ABC session",
    "section": "",
    "text": "The very first session of the ABC (Accessible Bioinformatics Cafe) will launch on june 13th, at 13:00 in the hall of AIAS (the Aarhus Institute of Advanced Studies, see below).\nEveryone is welcome to join independently of coding skills and level. In this first meeting we will also distribute a survey, so that participants can give some ideas about expectations and topics of interest."
  },
  {
    "objectID": "news/upcoming/2024-06-13-session1.html#purpose",
    "href": "news/upcoming/2024-06-13-session1.html#purpose",
    "title": "ABC.1: First ABC session",
    "section": "Purpose",
    "text": "Purpose\nThe ABC aims to:\n\nSupport and guide in using bioinformatics and programming tools.\nProvide support for coding-related issues.\nEnhance the coding skills of participants in fundamental programming languages (R, python, bash command line)."
  },
  {
    "objectID": "news/upcoming/2024-06-13-session1.html#who-can-benefit-from-the-abc",
    "href": "news/upcoming/2024-06-13-session1.html#who-can-benefit-from-the-abc",
    "title": "ABC.1: First ABC session",
    "section": "Who can benefit from the ABC?",
    "text": "Who can benefit from the ABC?\nEveryone, really. Those that will particularly benefit from the ABC include:\n\nBiologists, bioinformaticians, and health scientists who wish to adopt coding-based solutions.\nScientists and students who wish to accelerate the coding-based analysis of various types of data (such as OMICs data and other large-scale data) in research across Aarhus University and Aarhus University Hospital.\nStudents and researchers who want an open environment where it is easy to get assistance and talk with others encountering similar issues (or maybe who already solved them!)"
  },
  {
    "objectID": "news/upcoming/2024-06-13-session1.html#format",
    "href": "news/upcoming/2024-06-13-session1.html#format",
    "title": "ABC.1: First ABC session",
    "section": "Format",
    "text": "Format\nEach 2 hour session of the ABC will feature:\n\nTopic Presentation: Insightful presentations on various bioinformatics and coding topics.\nOpen Floor Session: A hands-on segment where staff from the Bioinformatics Core Facility and the Health Data Science Sandbox will be available to assist with any coding or bioinformatics issues."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the Accessible Bioinformatics Cafe",
    "section": "",
    "text": "An informal and collaborative cafe to help each other upskilling coding/bioinformatics skills. Hosted by scientists and bioinformaticians of the Health data science sandbox and Bioinformatics core facility at Aarhus University.\n\n \n\n\n\n\n\n\n\n\nHave you ever ended in a situation involving questions similar to those?\n\nWhere do I start to code on a command line?\n How do I learn the basic R/python commands?\n What the heck is this error?????\n\nDo you feel finding the right tools is like going through a maze of software installations, versions and incompatibilities?\n\n\n\nWhat follows is the natural desire of throwing your computer out of the window. Don’t worry! All the bioinformaticians/data scientists have gone through that, sometimes defined as part of the Kubler-Ross curve1, where frustration is the point in which coding becomes challenging and we might feel lost.\nThe idea behind ABC is to bridge you beyond frustration moments, while at the same time offering a relaxed environment and the possibility to learn new things, help and get to know each other:\n\n\n\n\n\n\n\n\nEveryone, really. Those that will particularly benefit from the ABC include:\n\nBiologists, bioinformaticians, and health scientists who wish to adopt coding-based solutions.\nScientists and students who wish to accelerate the coding-based analysis of various types of data (such as OMICs data and other large-scale data) in research across Aarhus University and Aarhus University Hospital.\nStudents and researchers who want an open environment where it is easy to get assistance and talk with others encountering similar issues (or maybe who already solved them!)\n\n\n\n\nEach ~2 hour session of the ABC will feature:\n\nTopic Presentation: Insightful presentations on various bioinformatics and coding topics.\nOpen Floor Session: A hands-on segment where staff from the Bioinformatics Core Facility and the Health Data Science Sandbox will be available to assist with any coding or bioinformatics issues.\n\n\n\n\n\nEvents Calendar. Look at our News for more information\n\n\nWhat\nWhen\nWhere\nTopics\nSignUp for cake!\n\n\n\n\nABC.1\n13.june 2024\nAIAS hall\nInstall R, R basics, Open cafe\nNone\n\n\nABC.2\n27.june 2024\nAIAS hall\nR projects and dplyr, Anaconda and python intro\nHere"
  },
  {
    "objectID": "index.html#concept",
    "href": "index.html#concept",
    "title": "Welcome to the Accessible Bioinformatics Cafe",
    "section": "",
    "text": "Have you ever ended in a situation involving questions similar to those?\n\nWhere do I start to code on a command line?\n How do I learn the basic R/python commands?\n What the heck is this error?????\n\nDo you feel finding the right tools is like going through a maze of software installations, versions and incompatibilities?\n\n\n\nWhat follows is the natural desire of throwing your computer out of the window. Don’t worry! All the bioinformaticians/data scientists have gone through that, sometimes defined as part of the Kubler-Ross curve1, where frustration is the point in which coding becomes challenging and we might feel lost.\nThe idea behind ABC is to bridge you beyond frustration moments, while at the same time offering a relaxed environment and the possibility to learn new things, help and get to know each other:"
  },
  {
    "objectID": "index.html#who-can-benefit-from-the-abc",
    "href": "index.html#who-can-benefit-from-the-abc",
    "title": "Welcome to the Accessible Bioinformatics Cafe",
    "section": "",
    "text": "Everyone, really. Those that will particularly benefit from the ABC include:\n\nBiologists, bioinformaticians, and health scientists who wish to adopt coding-based solutions.\nScientists and students who wish to accelerate the coding-based analysis of various types of data (such as OMICs data and other large-scale data) in research across Aarhus University and Aarhus University Hospital.\nStudents and researchers who want an open environment where it is easy to get assistance and talk with others encountering similar issues (or maybe who already solved them!)"
  },
  {
    "objectID": "index.html#format",
    "href": "index.html#format",
    "title": "Welcome to the Accessible Bioinformatics Cafe",
    "section": "",
    "text": "Each ~2 hour session of the ABC will feature:\n\nTopic Presentation: Insightful presentations on various bioinformatics and coding topics.\nOpen Floor Session: A hands-on segment where staff from the Bioinformatics Core Facility and the Health Data Science Sandbox will be available to assist with any coding or bioinformatics issues."
  },
  {
    "objectID": "index.html#calendar",
    "href": "index.html#calendar",
    "title": "Welcome to the Accessible Bioinformatics Cafe",
    "section": "",
    "text": "Events Calendar. Look at our News for more information\n\n\nWhat\nWhen\nWhere\nTopics\nSignUp for cake!\n\n\n\n\nABC.1\n13.june 2024\nAIAS hall\nInstall R, R basics, Open cafe\nNone\n\n\nABC.2\n27.june 2024\nAIAS hall\nR projects and dplyr, Anaconda and python intro\nHere"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Welcome to the Accessible Bioinformatics Cafe",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSomeone prefers to refer to the Dunning-Kruger effect instead, but this is for people overestimating their abilities. It is not the case of coders: we know that we cannot do something when we get stuck!↩︎"
  },
  {
    "objectID": "Documentation.html",
    "href": "Documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "While it is always worth remembering an event which offers free cake (especially when it recurs with a frequency like the ABC, as you could read here), you might want to read again what has been done and said after the sugar levels drop down.\nOur tutorials and instructions are self contained, thus useful for anyone, also people not attending a session.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nABC.1: Install R+Rstudio, first R coding problems/solutions\n\n\n\nR\n\n\nRStudio\n\n\nDataframe\n\n\n\nThings worth remembering from the ABC.1\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nABC.2: RStudio projects and Anaconda+Python\n\n\n\nR\n\n\nRStudio\n\n\nAnaconda\n\n\nPython\n\n\nenvironments\n\n\n\nThings worth remembering from the ABC.2\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "documentation/2024-06-13-instR.html",
    "href": "documentation/2024-06-13-instR.html",
    "title": "ABC.1: Install R+Rstudio, first R coding problems/solutions",
    "section": "",
    "text": "Introductory slides about the ABC, and who is behind the Health Data Science Sandbox and the Core Bioinformatics Facility\n \n\n Download Slides"
  },
  {
    "objectID": "documentation/2024-06-13-instR.html#rstudio-layout",
    "href": "documentation/2024-06-13-instR.html#rstudio-layout",
    "title": "ABC.1: Install R+Rstudio, first R coding problems/solutions",
    "section": "Rstudio Layout",
    "text": "Rstudio Layout\n\nLaunch RStudio.\nFamiliarize yourself with the RStudio interface, which consists of:\n\nSource Pane: Where you write and edit scripts.\nConsole Pane: Where you run commands and see output.\nEnvironment/History Pane: Shows your workspace and command history.\nFiles/Plots/Packages/Help/Viewer Pane: Access your files, view plots, manage packages, get help, and view HTML output."
  },
  {
    "objectID": "documentation/2024-06-13-instR.html#make-a-simple-script",
    "href": "documentation/2024-06-13-instR.html#make-a-simple-script",
    "title": "ABC.1: Install R+Rstudio, first R coding problems/solutions",
    "section": "Make a simple script",
    "text": "Make a simple script\n\nClick on File &gt; New File &gt; R Script to open a new script editor.\nInside the file you created, Write a simple script. Copy for example the script below:\n\nprint(\"Hello ABC\")\nx &lt;- 1:10\ny &lt;- x^2\nplot(x, y, type=\"b\", col=\"blue\")\n\nTry to run the script (The small Run button). Two things should happen:\n\nAn output is shown in the console (bottom left)\nA plot is created and shown in the plotting window (bottom right)\nthe variables x and y are saved in your environment and can be seen in the variable explorer (top right). These variables can be used again since they exist in your computer’s memory.\n\n\n\n\n\n\n\n\nWorking directory\n\n\n\nEvery time you start working in R, this will be considering a working directory. Such directory is the reference point you are working in. For example, if you want to open a file, you need to know where it is in relation to your working directory, so that you can correctly write where it is. Write the command getwd() in the console and press Enter to see your current working directory."
  },
  {
    "objectID": "documentation/2024-06-13-instR.html#some-basic-operations",
    "href": "documentation/2024-06-13-instR.html#some-basic-operations",
    "title": "ABC.1: Install R+Rstudio, first R coding problems/solutions",
    "section": "Some basic operations",
    "text": "Some basic operations\nIn R you can perform basic math operations by using the appropriate symbol. For example\n2+3\n9*2\n5^2\nYou can assign variables (“objects”) using the symbol &lt;-. For example\n\nx &lt;- 5\nanothername &lt;- 3\nitCanBeAnything &lt;- \"It can be text\""
  },
  {
    "objectID": "documentation/2024-06-13-instR.html#lets-try-some-exercises",
    "href": "documentation/2024-06-13-instR.html#lets-try-some-exercises",
    "title": "ABC.1: Install R+Rstudio, first R coding problems/solutions",
    "section": "Lets try some exercises!",
    "text": "Lets try some exercises!\nCreate a new script file or use the console to test some exercises below.\n\n1. Create a data frame\nWe will create a simple data frame. A data frame is nothing more than a table, where both rows and columns have labels, and can be easily accessed and manipulated. To create a small data frame, we can define its columns. We define each column through a vector with the function c(), where we can write values inside separated by a comma. Then we provide all vectors to the function data.frame, where we assign column names (Gene, Control, Treatment1, Treatment2).\n\n\n\n\n\n\nNote\n\n\n\nMake sure your vectors are all of the same length! Also, each vector usually contains values of the same type (for example only numbers or only text)\n\n\n\ngeneExpr &lt;- data.frame(\n  Gene = c(\"GeneA\", \"GeneB\", \"GeneC\"),\n  Control = c(10, 20, 30),\n  Treatment1 = c(15, 25, 35),\n  Treatment2 = c(100, 0, 250)\n)\n\ngeneExpr\n\n   Gene Control Treatment1 Treatment2\n1 GeneA      10         15        100\n2 GeneB      20         25          0\n3 GeneC      30         35        250\n\n\nYou should be able to see the small data frame printed in output and also shown in the variable explorer.\n\n\n2. Plot from a data frame\nNow lets try to plot it Treatment 1 versus Treatment 2. The basic function for plotting in R is called plot. It takes as arguments the x axis and the y axis. It has other options which are not mandatory, such as style and color of the plot. Notice how we access the values in the columns using the $ sign.\n\nplot( x = geneExpr$Treatment1, \n      y = geneExpr$Treatment2 , \n      main=\"Expression per Treatment group\", \n      xlab = \"Treatment 1\", \n      ylab = \"Treatment 2\" , \n      col =\"blue\" , \n      type =\"b\")\n\n\n\n\n\n\n\n\nYou should be able to see a plot in the plotting window. In the command above we used many options beyond x and y. Can you see what they match in the plot?\n\n\n3. Summary statistics\nThere are lots of summary statistics already implemented in R. Below we calculate mean, median and standard deviation for the column Treatment1 of the data frame and then we print them.\n\nx &lt;- geneExpr$Treatment1\nmeanTr1 &lt;- mean(x)\nmedianTr1 &lt;- median(x)\nsdTr1 &lt;- sd(x)\n\nprint(\"mean, median and sd:\")\n\n[1] \"mean, median and sd:\"\n\nprint(c(meanTr1, medianTr1, sdTr1))\n\n[1] 25 25 10\n\n\nThis was neat! Can you try to calculate the cumulative sum of the difference between Treatment 1 and Treatment 2?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nx &lt;- geneExpr$Treatment1 - geneExpr$Treatment2\ncsum &lt;- cumsum(x)\nprint(\"cumulative sum of Tr1 - Tr2:\")\n\n[1] \"cumulative sum of Tr1 - Tr2:\"\n\nprint(csum)\n\n[1]  -85  -60 -275\n\n\n\n\n\n\n\n4. Define your own function!\nAlthough R and the packages you can find have almost everything you will need, sometimes you might need to define your own function. The syntax to do it is very easy: you assign a function to a name, which then you will be able to use. Below, there is a function taking an argument (arg1) and multiplying it by 5. The function commands need to be between the curly brackets, and what we want as output need to be explicit through the return() function.\n\nmyFunction &lt;- function(arg1){\n  \n  # Now arg1 is a variable of the function. \n  # You can write comments inside code blocks with #\n  output &lt;- arg1 * 5\n  return (output)\n\n}\n\nSuch a function works if the argument is a number, but also if it is a vector!\n\nprint(\"with a number only\")\n\n[1] \"with a number only\"\n\nmyFunction(5)\n\n[1] 25\n\nprint(\"with a vector\")\n\n[1] \"with a vector\"\n\nmyFunction(geneExpr$Treatment1)\n\n[1]  75 125 175\n\n\nTry to make a function that takes three vectors, plots the first against the sum of the second and third, and returns the sum of all three vectors. Use the plot command we applied previously for help.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nsimpleSumPlot &lt;- function (arg1, arg2, arg3){\n  \n  arg23 &lt;- arg2 + arg3\n  arg123 &lt;- arg1 + arg2 + arg3\n\n  #plotting\n  plot( x = arg1, \n      y = arg23, \n      main=\"Plot with my own function\", \n      xlab = \"arg1\", \n      ylab = \"arg2+arg3\" , \n      col =\"red\", \n      type =\"o\" )\n\n  return (arg123)\n  \n}\n\nNow you can try this on vectors of the same length. We can use the ones in our data frame!\n\nsimpleSumPlot(arg1=geneExpr$Control, \n              arg2=geneExpr$Treatment1, \n              arg3=geneExpr$Treatment2)\n\n\n\n\n\n\n\n\n[1] 125  45 315\n\n\n\n\n\n\n\n5. Read files\nMany times we want to read files from excel or other formats. R has many ways to do this and if not there are always packages out there to help you read the format you have. For reading an excel file a great package is the readxl. To read a csv file there is already the R function read.csv().\n\n\n\n\n\n\nNote\n\n\n\nBut wait. what are packages? Each package consist of a set of R and other scripts that meet specific needs for the users of R. For example openxlsx reads from Excel files, which R cannot do on its own. There are thousands of packages out there, ranging all fields of science, and some have become very popular.\n\n\nTry to install the package openxlsx. You can use the command install.packages(\"openxlsx\") in your RStudio console. Otherwise, go on the bottom right panel and click Packages and Install like this\n\nNow you are ready to import an Excel file. To use the package, we can load it with library(openxlsx). Otherwise we need to write the package name before the command to use from it (as done below). You can get a file locally on your computer or from an URL as done in this example.\n\ndf &lt;- openxlsx::read.xlsx(\"https://github.com/AU-ABC/AU-ABC.github.io/raw/main/documentation/2024-06-13-instR/data/data.xlsx\", sheet=1)\ndf\n\n   x  y  z\n1 10 30 -1\n2 20 20  0\n3 30 10  1\n\n\nOnce you have a data frame, you can always save it. Remember, the path of the saved file is related to your current working directory! To save your data frame as a csv file, use\n\nwrite.table(geneExpr, \n            file = \"./myFirstDataFrame.csv\", \n            row.names = FALSE , \n            sep=\"\\t\")\n\nwhere we remove the labels for the rows and use the tab separator instead of the comma. To read the file again, simply use\n\ndf2 &lt;- read.csv(\"./myFirstDataFrame.csv\" , sep=\"\\t\")\ndf2\n\n   Gene Control Treatment1 Treatment2\n1 GeneA      10         15        100\n2 GeneB      20         25          0\n3 GeneC      30         35        250\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use the tab key of your keyboard to see a list of the available paths"
  },
  {
    "objectID": "tips/python.html",
    "href": "tips/python.html",
    "title": "Useful tips for python",
    "section": "",
    "text": "Useful tips for python"
  }
]